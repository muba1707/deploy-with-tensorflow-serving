{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "detect_fingers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIMqUk338FAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"@Author: @UdayKiran\"\n",
        "\n",
        "#Importing libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import copy\n",
        "import math\n",
        "from itertools import groupby\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class CaptureHand():\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def setParameters(self, parameters):\n",
        "        # parameters for detecting hand in video\n",
        "        self.hand_box_x = parameters.get(\"hand_box_x\",0.6)  # start point/total width\n",
        "        self.hand_box_y = parameters.get(\"hand_box_y\",0.7) # start point/total width\n",
        "        self.threshold = parameters.get(\"threshold\",40)  #  BINARY threshold\n",
        "        self.blur_alue = parameters.get(\"blur_value\",41)  # GaussianBlur parameter\n",
        "        self.background_threshold = parameters.get(\"background_threshold\",50)\n",
        "        self.learning_rate = parameters.get(\"learning_rate\",0)\n",
        "\n",
        "        # variables\n",
        "        self.is_bg_captured = 0   # bool, whether the background captured\n",
        "        self.trigger_switch = False  # if true, keyborad simulator works\n",
        "\n",
        "        self.morse_codes = {\"12\":\"A\",\"2111\":\"B\",\"2121\":\"C\",\"211\":\"D\",\"1\":\"E\",\"1121\":\"F\",\"221\":\"G\",\"1111\":\"H\",\"11\":\"I\", \"1222\":\"J\",\"212\":\"K\", \"1211\":\"L\",\"22\":\"M\",\"21\":\"N\",\"222\":\"O\",\"1221\":\"P\",\"2212\":\"Q\",\"121\":\"R\",\"111\":\"S\",\"2\":\"T\",\"112\":\"U\",\"1112\":\"V\", \"122\":\"W\",\"2112\":\"X\",\"2122\":\"Y\",\"2211\":\"Z\",\"1222\":\"1\",\"11222\":\"2\",\"11122\":\"3\",\"11112\":\"4\",\"11111\":\"5\",\"21111\":\"6\",\"22111\":\"7\",\"22211\":\"8\",\"22221\":\"9\",\"22222\":\"0\"} #Morse codes for Alphabets and numbers\n",
        "\n",
        "    def printThreshold(self,thr):\n",
        "        print(\"! Changed threshold to \"+str(thr))\n",
        "\n",
        "    def remove_back_ground(self, frame, bgModel):\n",
        "        fgmask = bgModel.apply(frame,learningRate=self.learning_rate)\n",
        "        kernel = np.ones((3, 3), np.uint8)\n",
        "        fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
        "        res = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
        "        return res\n",
        "\n",
        "    def load_model(self, path):\n",
        "        model = tf.keras.models.load_model(path)\n",
        "        print(model.summary())\n",
        "        classes = [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\"] #class labels\n",
        "        return model, classes\n",
        "\n",
        "    def capture_video(self, path):\n",
        "        camera = cv2.VideoCapture(0) #start capturing video\n",
        "        camera.set(10,200)\n",
        "        cv2.namedWindow('trackbar')\n",
        "        cv2.createTrackbar('trh1', 'trackbar', self.threshold, 100, self.printThreshold)\n",
        "        model, classes = self.load_model(path) #loading pretrained model to predict no of fingers opened\n",
        "        store_predicted_classes = [] #to store predicted classes\n",
        "        final_text = '' #adding each character to the final text\n",
        "        start_new_char = False\n",
        "        text_image = np.zeros((512, 512, 1), dtype = \"uint8\")\n",
        "\n",
        "        while camera.isOpened():\n",
        "            ret, frame = camera.read()\n",
        "            threshold = cv2.getTrackbarPos('trh1', 'trackbar')\n",
        "            frame = cv2.bilateralFilter(frame, 5, 50, 100)  # smoothing filter\n",
        "            frame = cv2.flip(frame, 1)  # flip the frame horizontally\n",
        "            cv2.rectangle(frame, (int(self.hand_box_x * frame.shape[1]), 0),\n",
        "                         (frame.shape[1], int(self.hand_box_y * frame.shape[0])), (255, 0, 0), 2)\n",
        "            cv2.imshow('original_video', frame)\n",
        "\n",
        "            #  Main operation\n",
        "            if self.is_bg_captured == 1:  # this part wont run until background captured\n",
        "                img = self.remove_back_ground(frame, bgModel)\n",
        "                img = img[0:int(self.hand_box_y * frame.shape[0]),\n",
        "                            int(self.hand_box_x * frame.shape[1]):frame.shape[1]]  # clip the ROI\n",
        "                cv2.imshow('mask', img)\n",
        "                cv2.waitKey(250)#To reduce the frame numbers to capure the hand perfectly.\n",
        "                # convert the image into binary image\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                blur = cv2.GaussianBlur(gray, (self.blur_alue, self.blur_alue), 0)\n",
        "                cv2.imshow('blur', blur)\n",
        "                ret, thresh = cv2.threshold(blur, self.threshold, 255, cv2.THRESH_BINARY)\n",
        "                cv2.imshow('ori', thresh)\n",
        "                img2= cv2.resize(thresh,dsize=(150,150), interpolation = cv2.INTER_CUBIC) #resizing image to fin into tensorflow model 150X150\n",
        "                #Numpy array\n",
        "                np_image_data = np.asarray(img2)\n",
        "                #maybe insert float convertion here - see edit remark!\n",
        "                np_final = np.expand_dims(np_image_data,axis=0)\n",
        "                input_data = np_final.reshape((np_final.shape[0], np_final.shape[1], np_final.shape[2], 1))\n",
        "                input_data = tf.cast(input_data, tf.float32)\n",
        "\n",
        "                class_pred = classes[np.argmax(model.predict(input_data)[0])] #predict the class of the image\n",
        "                cv2.putText(thresh, str(class_pred), (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (245,210,65), 2, 1)#print the predicted class on image\n",
        "                cv2.imshow('predict', thresh)\n",
        "\n",
        "                #This logic is to predict the morse code\n",
        "                if class_pred == \"4\": #To add space to your morse code\n",
        "                    final_text+=\" \"\n",
        "                if class_pred == \"3\": #To start cpturing the fingures for next morse character\n",
        "                    start_new_char = True\n",
        "                    store_predicted_classes=[]\n",
        "                if start_new_char and class_pred==\"5\": #To stop cpturing the fingures for current morse character and predict the morse code for captured fingers\n",
        "                    char = \"\"\n",
        "                    store_predicted_classes = [x[0] for x in groupby(store_predicted_classes)] #Remove consecutive duplicates\n",
        "                    for i in store_predicted_classes:\n",
        "                        if i!=\"0\" and i!=\"3\" and i!=\"4\":\n",
        "                            char+=i\n",
        "                    predicted_char = self.morse_codes[char] #get morse code\n",
        "                    final_text+=predicted_char\n",
        "                    store_predicted_classes=[]\n",
        "                    start_new_char = False\n",
        "                if start_new_char and (class_pred==\"1\" or class_pred==\"2\" or class_pred==\"0\"):\n",
        "                    store_predicted_classes.append(class_pred)\n",
        "                cv2.putText(text_image, final_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (245,210,65), 2, 1)\n",
        "                cv2.imshow('test', text_image)\n",
        "\n",
        "            # This code is to capture background and reset backgroud\n",
        "            k = cv2.waitKey(10)\n",
        "            if k == 27:  # press ESC to exit\n",
        "                camera.release()\n",
        "                cv2.destroyAllWindows()\n",
        "                break\n",
        "            elif k == ord('b'):  # press 'b' to capture the background\n",
        "                bgModel = cv2.createBackgroundSubtractorMOG2(0, self.background_threshold)\n",
        "                self.is_bg_captured = 1\n",
        "                print( '!!!Background Captured!!!')\n",
        "            elif k == ord('r'):  # press 'r' to reset the background\n",
        "                bgModel = None\n",
        "                self.trigger_switch = False\n",
        "                self.is_bg_captured = 0\n",
        "                print ('!!!Reset BackGround!!!')\n",
        "            elif k == ord('n'):\n",
        "                self.trigger_switch = True\n",
        "                print ('!!!Trigger On!!!')\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    parameters = {\"hand_box_x\":0.6,\"hand_box_y\":0.7,\"threshold\":40,\"blur_value\":41,\"background_threshold\":50,\"learning_rate\":0} #predefinied parameters(You can try different values)\n",
        "    model_path = \"my_model.h5\" #pretrained model path\n",
        "    obj = CaptureHand()\n",
        "    obj.setParameters(parameters)\n",
        "    obj.capture_video(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
